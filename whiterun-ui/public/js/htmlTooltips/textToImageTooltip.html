<strong>Generate a new image from a text prompt</strong>
<br><br><Strong>Inputs:</Strong>
<br><Strong>Input Prompt - </Strong>A text object or list
<br><Strong>Example Input Prompt - </Strong>Can take an <Strong>Image Prompt Operator or Prompt Grouper Operator</Strong>.
<br><br><Strong>Output - </Strong>An image file
<br><Strong>Example Connections - </Strong>Can be connected to an <Strong>Image Display Operator</Strong> in
 order to display it. If you want to continue modifying it, you can connect it to an <Strong>Upscaler Operator or an Image to Image Masking Operator</Strong>
<br>
<br><Strong>Height - </Strong>Determines height of generated image (Determined by Engine)
<br><Strong>Width - </Strong>Determines width of generated image (Determined by Engine)
<br><Strong>Style - </Strong>Guides the model towards a particular style when generating the image, only applicable for non-SDXL engines.
<br><Strong>Engine - </Strong>Which Stable Diffusion model to use, SDXL 1.0 is recommended for most use cases.
<br><Strong>Clip Guidance - </Strong>Determines how the model modifies the prompt internally to achieve better results. Only applicable for non-SDXL engines.
<br><Strong>Sampler - </Strong>Determines patterns used to generate the image. Each sampler outputs a different quality at varying speeds so experimentation is needed.
<br><Strong>CFG Scale - </Strong>How closely the model follows the given prompt when generating the image, lower
values mean higher creativity while higher values require more detailed prompts. A good range is between 5 and 12.
<br><Strong>Seed - </Strong>Value determines noise seed, leave the same if you want to generate the same image
given the same prompt, otherwise we recommend leaving it as 0 for a random seed.
<br><Strong>Steps - </Strong>How many diffusion steps to run, more steps means more quality but longer time to generate.